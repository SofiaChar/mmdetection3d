- step:
    name: prep_kitti_dataset
    image: valohai/mmdetection3d
    environment: aws-eu-west-1-g4dn-12xlarge
    command:
    - apt-get update
    - apt-get install -y unzip wget zip tar
    - if [ -d "/valohai/inputs/kitti_dataset" ]; then
    - echo "Input directory exists:/valohai/inputs/kitti_dataset"
    - ls /valohai/inputs/kitti_dataset
    - mkdir -p /tmp/kitti
    - for f in /valohai/inputs/kitti_dataset/*.zip; do
    - echo "Unzipping $f..."
    - unzip "$f" -d /tmp/kitti/
    - done
    - echo "Folder structure after unzipping:"
    - ls -R /tmp/kitti
    - else
    - echo "Input directory does not exist:/valohai/inputs/kitti_dataset"
    - exit 1
    - fi
    - mkdir -p /tmp/kitti/training/calib
    - mkdir -p /tmp/kitti/testing/calib
    - mkdir -p /tmp/kitti/training/image_2
    - mkdir -p /tmp/kitti/testing/image_2
    - mkdir -p /tmp/kitti/training/label_2
    - mkdir -p /tmp/kitti/training/velodyne
    - mkdir -p /tmp/kitti/testing/velodyne
    - mkdir -p /tmp/kitti/ImageSets
    - echo "Folder structure after creating directories:"
    - ls -R /tmp/kitti
    - if [ -d "/valohai/repository/data/kitti/training/calib" ]; then
    - cp /valohai/repository/data/kitti/training/calib/* /tmp/kitti/training/calib/
    - fi
    - if [ -d "/valohai/repository/data/kitti/testing/calib" ]; then
    - cp /valohai/repository/data/kitti/testing/calib/* /tmp/kitti/testing/calib/
    - fi
    - if [ -d "/valohai/repository/data/kitti/training/image_2" ]; then
    - cp /valohai/repository/data/kitti/training/image_2/* /tmp/kitti/training/image_2/
    - fi
    - if [ -d "/valohai/repository/data/kitti/testing/image_2" ]; then
    - cp /valohai/repository/data/kitti/testing/image_2/* /tmp/kitti/testing/image_2/
    - fi
    - if [ -d "/valohai/repository/data/kitti/training/velodyne" ]; then
    - cp /valohai/repository/data/kitti/training/velodyne/* /tmp/kitti/training/velodyne/
    - fi
    - if [ -d "/valohai/repository/data/kitti/testing/velodyne" ]; then
    - cp /valohai/repository/data/kitti/testing/velodyne/* /tmp/kitti/testing/velodyne/
    - fi
    - echo "Folder structure after copying files:"
    - ls -R /tmp/kitti
    - cd /tmp/kitti/ImageSets
    - wget -c https://raw.githubusercontent.com/traveller59/second.pytorch/master/second/data/ImageSets/test.txt --no-check-certificate --content-disposition -O test.txt
    - wget -c https://raw.githubusercontent.com/traveller59/second.pytorch/master/second/data/ImageSets/train.txt --no-check-certificate --content-disposition -O train.txt
    - wget -c https://raw.githubusercontent.com/traveller59/second.pytorch/master/second/data/ImageSets/val.txt --no-check-certificate --content-disposition -O val.txt
    - wget -c https://raw.githubusercontent.com/traveller59/second.pytorch/master/second/data/ImageSets/trainval.txt --no-check-certificate --content-disposition -O trainval.txt
    - echo "Contents of ImageSets folder:"
    - ls /tmp/kitti/ImageSets
    - python /valohai/repository/tools/create_data.py kitti --root-path /tmp/kitti --out-dir /tmp/kitti --extra-tag kitti
    - cd /tmp
    - tar -cvf kitti_processed.tar kitti/
    - mv kitti_processed.tar /valohai/outputs/
    - python /valohai/repository/valohai_utils/save_dataset_metadata.py --file_path /valohai/outputs/kitti_processed.tar --dataset_name kitti_processed --dataset_version v2
    inputs:
      - name: kitti_dataset
        default:
          - https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_calib.zip
          - https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip
          - https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_label_2.zip
          - https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_velodyne.zip

- step:
    name: train
    image: valohai/mmdetection3d
    environment: aws-eu-west-1-g4dn-xlarge
    command:
      - set -x
      - apt-get update
      - apt-get install -y unzip wget zip tar
      - pip install valohai-utils watchdog
      - mkdir /valohai/repository/checkpoints/
      - cp /valohai/inputs/model_weights/* /valohai/repository/checkpoints/
      - mkdir -p /valohai/repository/data/
      - tar -xf /valohai/inputs/kitti_dataset/kitti_processed.tar -C /valohai/repository/data/
      - nohup python ./valohai_utils/log_handler.py &
      - python3 tools/train.py --cfg-options {parameters}
    parameters:
      - category: optim_wrapper
        default: 0.003
        name: lr
        optional: yes
        pass-as: optim_wrapper.optimizer.lr={v}
        type: float

      - category: visualizer
        default: Det3DLocalVisualizer
        name: type
        optional: yes
        pass-as: visualizer.type={v}
        type: string

      - category: optim_wrapper
        default: 0.01
        name: weight_decay
        optional: yes
        pass-as: optim_wrapper.optimizer.weight_decay={v}
        type: float

      - category: optim_wrapper
        default: '[0.95, 0.99]'
        multiple: separate
        multiple-separator: ','
        name: betas
        optional: yes
        pass-as: optim_wrapper.optimizer.betas={v}
        type: string

      - category: optim_wrapper
        default: 35
        name: max_norm
        optional: yes
        pass-as: optim_wrapper.clip_grad.max_norm={v}
        type: integer

      - category: optim_wrapper
        default: 2
        name: norm_type
        optional: yes
        pass-as: optim_wrapper.clip_grad.norm_type={v}
        type: integer

      - category: param_scheduler
        default: '[{''type'': ''LinearLR'', ''start_factor'': 0.1, ''by_epoch'': False, ''begin'': 0,
          ''end'': 1000}, {''type'': ''CosineAnnealingLR'', ''begin'': 0, ''T_max'': 40, ''end'': 40,
          ''by_epoch'': True, ''eta_min'': 1e-05}]'
        multiple: separate
        multiple-separator: ','
        name: param_scheduler
        optional: yes
        pass-as: param_scheduler={v}
        type: string

      - category: train_cfg
        default: 40
        name: max_epochs
        optional: yes
        pass-as: train_cfg.max_epochs={v}
        type: integer

      - category: train_cfg
        default: 1
        name: val_interval
        optional: yes
        pass-as: train_cfg.val_interval={v}
        type: integer

      - category: auto_scale_lr
        default: 0
        name: enable
        optional: yes
        pass-as: auto_scale_lr.enable={v}
        type: integer

      - category: auto_scale_lr
        default: 16
        name: base_batch_size
        optional: yes
        pass-as: auto_scale_lr.base_batch_size={v}
        type: integer

      - category: default_scope
        default: mmdet3d
        name: default_scope
        optional: yes
        pass-as: default_scope={v}
        type: string

      - category: default_hooks
        default: -1
        name: interval
        optional: yes
        pass-as: default_hooks.checkpoint.interval={v}
        type: integer

      - category: env_cfg
        default: 0
        name: cudnn_benchmark
        optional: yes
        pass-as: env_cfg.cudnn_benchmark={v}
        type: integer

      - category: env_cfg
        default: fork
        name: mp_start_method
        optional: yes
        pass-as: env_cfg.mp_cfg.mp_start_method={v}
        type: string

      - category: env_cfg
        default: 0
        name: opencv_num_threads
        optional: yes
        pass-as: env_cfg.mp_cfg.opencv_num_threads={v}
        type: integer

      - category: env_cfg
        default: nccl
        name: backend
        optional: yes
        pass-as: env_cfg.dist_cfg.backend={v}
        type: string

      - category: log_processor
        default: 50
        name: window_size
        optional: yes
        pass-as: log_processor.window_size={v}
        type: integer

      - category: log_processor
        default: 1
        name: by_epoch
        optional: yes
        pass-as: log_processor.by_epoch={v}
        type: integer

      - category: log_level
        default: INFO
        name: log_level
        optional: yes
        pass-as: log_level={v}
        type: string

      - category: load_from
        default: https://download.openmmlab.com/mmdetection3d/pretrain_models/mvx_faster_rcnn_detectron2-caffe_20e_coco-pretrain_gt-sample_kitti-3-class_moderate-79.3_20200207-a4a6a3c7.pth
        name: load_from
        optional: yes
        pass-as: load_from={v}
        type: string

      - category: resume
        default: 0
        name: resume
        optional: yes
        pass-as: resume={v}
        type: integer

      - category: model
        default: '[0.05, 0.05, 0.1]'
        multiple: separate
        multiple-separator: ','
        name: voxel_size
        optional: yes
        pass-as: model.pts_voxel_encoder.voxel_size={v}
        type: string

      - category: model
        default: '[0, -40, -3, 70.4, 40, 1]'
        multiple: separate
        multiple-separator: ','
        name: point_cloud_range
        optional: yes
        pass-as: model.pts_voxel_encoder.point_cloud_range={v}
        type: string

      - category: model
        default: 1
        name: voxel
        optional: yes
        pass-as: model.data_preprocessor.voxel={v}
        type: integer

      - category: model
        default: dynamic
        name: voxel_type
        optional: yes
        pass-as: model.data_preprocessor.voxel_type={v}
        type: string

      - category: model
        default: -1
        name: max_num_points
        optional: yes
        pass-as: model.data_preprocessor.voxel_layer.max_num_points={v}
        type: integer

      - category: model
        default: '[-1, -1]'
        multiple: separate
        multiple-separator: ','
        name: max_voxels
        optional: yes
        pass-as: model.data_preprocessor.voxel_layer.max_voxels={v}
        type: string

      - category: model
        default: '[102.9801, 115.9465, 122.7717]'
        multiple: separate
        multiple-separator: ','
        name: mean
        optional: yes
        pass-as: model.data_preprocessor.mean={v}
        type: string

      - category: model
        default: '[1.0, 1.0, 1.0]'
        multiple: separate
        multiple-separator: ','
        name: std
        optional: yes
        pass-as: model.data_preprocessor.std={v}
        type: string

      - category: model
        default: 0
        name: bgr_to_rgb
        optional: yes
        pass-as: model.data_preprocessor.bgr_to_rgb={v}
        type: integer

      - category: model
        default: 32
        name: pad_size_divisor
        optional: yes
        pass-as: model.data_preprocessor.pad_size_divisor={v}
        type: integer

      - category: model
        default: 50
        name: depth
        optional: yes
        pass-as: model.img_backbone.depth={v}
        type: integer

      - category: model
        default: 4
        name: num_stages
        optional: yes
        pass-as: model.img_backbone.num_stages={v}
        type: integer

      - category: model
        default: '[0, 1, 2, 3]'
        multiple: separate
        multiple-separator: ','
        name: out_indices
        optional: yes
        pass-as: model.img_backbone.out_indices={v}
        type: string

      - category: model
        default: 1
        name: frozen_stages
        optional: yes
        pass-as: model.img_backbone.frozen_stages={v}
        type: integer

      - category: model
        default: 0
        name: requires_grad
        optional: yes
        pass-as: model.img_neck.norm_cfg.requires_grad={v}
        type: integer

      - category: model
        default: 1
        name: norm_eval
        optional: yes
        pass-as: model.img_backbone.norm_eval={v}
        type: integer

      - category: model
        default: caffe
        name: style
        optional: yes
        pass-as: model.img_backbone.style={v}
        type: string

      - category: model
        default: 512
        name: in_channels
        optional: yes
        pass-as: model.pts_bbox_head.in_channels={v}
        type: integer

      - category: model
        default: '[256, 256]'
        multiple: separate
        multiple-separator: ','
        name: out_channels
        optional: yes
        pass-as: model.pts_neck.out_channels={v}
        type: string

      - category: model
        default: 5
        name: num_outs
        optional: yes
        pass-as: model.img_neck.num_outs={v}
        type: integer

      - category: model
        default: 512
        name: feat_channels
        optional: yes
        pass-as: model.pts_bbox_head.feat_channels={v}
        type: integer

      - category: model
        default: 0
        name: with_distance
        optional: yes
        pass-as: model.pts_voxel_encoder.with_distance={v}
        type: integer

      - category: model
        default: 1
        name: with_cluster_center
        optional: yes
        pass-as: model.pts_voxel_encoder.with_cluster_center={v}
        type: integer

      - category: model
        default: 1
        name: with_voxel_center
        optional: yes
        pass-as: model.pts_voxel_encoder.with_voxel_center={v}
        type: integer

      - category: model
        default: 256
        name: img_channels
        optional: yes
        pass-as: model.pts_voxel_encoder.fusion_layer.img_channels={v}
        type: integer

      - category: model
        default: 64
        name: pts_channels
        optional: yes
        pass-as: model.pts_voxel_encoder.fusion_layer.pts_channels={v}
        type: integer

      - category: model
        default: 128
        name: mid_channels
        optional: yes
        pass-as: model.pts_voxel_encoder.fusion_layer.mid_channels={v}
        type: integer

      - category: model
        default: '[0, 1, 2, 3, 4]'
        multiple: separate
        multiple-separator: ','
        name: img_levels
        optional: yes
        pass-as: model.pts_voxel_encoder.fusion_layer.img_levels={v}
        type: string

      - category: model
        default: 0
        name: align_corners
        optional: yes
        pass-as: model.pts_voxel_encoder.fusion_layer.align_corners={v}
        type: integer

      - category: model
        default: 1
        name: activate_out
        optional: yes
        pass-as: model.pts_voxel_encoder.fusion_layer.activate_out={v}
        type: integer

      - category: model
        default: 0
        name: fuse_out
        optional: yes
        pass-as: model.pts_voxel_encoder.fusion_layer.fuse_out={v}
        type: integer

      - category: model
        default: '[41, 1600, 1408]'
        multiple: separate
        multiple-separator: ','
        name: sparse_shape
        optional: yes
        pass-as: model.pts_middle_encoder.sparse_shape={v}
        type: string

      - category: model
        default: '[''conv'', ''norm'', ''act'']'
        multiple: separate
        multiple-separator: ','
        name: order
        optional: yes
        pass-as: model.pts_middle_encoder.order={v}
        type: string

      - category: model
        default: '[5, 5]'
        multiple: separate
        multiple-separator: ','
        name: layer_nums
        optional: yes
        pass-as: model.pts_backbone.layer_nums={v}
        type: string

      - category: model
        default: '[1, 2]'
        multiple: separate
        multiple-separator: ','
        name: layer_strides
        optional: yes
        pass-as: model.pts_backbone.layer_strides={v}
        type: string

      - category: model
        default: '[1, 2]'
        multiple: separate
        multiple-separator: ','
        name: upsample_strides
        optional: yes
        pass-as: model.pts_neck.upsample_strides={v}
        type: string

      - category: model
        default: 3
        name: num_classes
        optional: yes
        pass-as: model.pts_bbox_head.num_classes={v}
        type: integer

      - category: model
        default: 1
        name: use_direction_classifier
        optional: yes
        pass-as: model.pts_bbox_head.use_direction_classifier={v}
        type: integer

      - category: model
        default: '[[0, -40.0, -0.6, 70.4, 40.0, -0.6], [0, -40.0, -0.6, 70.4, 40.0, -0.6], [0, -40.0,
          -1.78, 70.4, 40.0, -1.78]]'
        multiple: separate
        multiple-separator: ','
        name: ranges
        optional: yes
        pass-as: model.pts_bbox_head.anchor_generator.ranges={v}
        type: string

      - category: model
        default: '[[0.8, 0.6, 1.73], [1.76, 0.6, 1.73], [3.9, 1.6, 1.56]]'
        multiple: separate
        multiple-separator: ','
        name: sizes
        optional: yes
        pass-as: model.pts_bbox_head.anchor_generator.sizes={v}
        type: string

      - category: model
        default: '[0, 1.57]'
        multiple: separate
        multiple-separator: ','
        name: rotations
        optional: yes
        pass-as: model.pts_bbox_head.anchor_generator.rotations={v}
        type: string

      - category: model
        default: 0
        name: reshape_out
        optional: yes
        pass-as: model.pts_bbox_head.anchor_generator.reshape_out={v}
        type: integer

      - category: model
        default: 1
        name: assigner_per_size
        optional: yes
        pass-as: model.pts_bbox_head.assigner_per_size={v}
        type: integer

      - category: model
        default: 1
        name: diff_rad_by_sin
        optional: yes
        pass-as: model.pts_bbox_head.diff_rad_by_sin={v}
        type: integer

      - category: model
        default: 1
        name: assign_per_class
        optional: yes
        pass-as: model.pts_bbox_head.assign_per_class={v}
        type: integer

      - category: model
        default: 0
        name: use_sigmoid
        optional: yes
        pass-as: model.pts_bbox_head.loss_dir.use_sigmoid={v}
        type: integer

      - category: model
        default: 2.0
        name: gamma
        optional: yes
        pass-as: model.pts_bbox_head.loss_cls.gamma={v}
        type: float

      - category: model
        default: 0.25
        name: alpha
        optional: yes
        pass-as: model.pts_bbox_head.loss_cls.alpha={v}
        type: float

      - category: model
        default: 0.2
        name: loss_weight
        optional: yes
        pass-as: model.pts_bbox_head.loss_dir.loss_weight={v}
        type: float

      - category: model
        default: 0.1111111111111111
        name: beta
        optional: yes
        pass-as: model.pts_bbox_head.loss_bbox.beta={v}
        type: float

      - category: model
        default: '[{''type'': ''Max3DIoUAssigner'', ''iou_calculator'': {''type'': ''BboxOverlapsNearest3D''},
          ''pos_iou_thr'': 0.35, ''neg_iou_thr'': 0.2, ''min_pos_iou'': 0.2, ''ignore_iof_thr'': -1},
          {''type'': ''Max3DIoUAssigner'', ''iou_calculator'': {''type'': ''BboxOverlapsNearest3D''},
          ''pos_iou_thr'': 0.35, ''neg_iou_thr'': 0.2, ''min_pos_iou'': 0.2, ''ignore_iof_thr'': -1},
          {''type'': ''Max3DIoUAssigner'', ''iou_calculator'': {''type'': ''BboxOverlapsNearest3D''},
          ''pos_iou_thr'': 0.6, ''neg_iou_thr'': 0.45, ''min_pos_iou'': 0.45, ''ignore_iof_thr'': -1}]'
        multiple: separate
        multiple-separator: ','
        name: assigner
        optional: yes
        pass-as: model.train_cfg.pts.assigner={v}
        type: string

      - category: model
        default: 0
        name: allowed_border
        optional: yes
        pass-as: model.train_cfg.pts.allowed_border={v}
        type: integer

      - category: model
        default: -1
        name: pos_weight
        optional: yes
        pass-as: model.train_cfg.pts.pos_weight={v}
        type: integer

      - category: model
        default: 0
        name: debug
        optional: yes
        pass-as: model.train_cfg.pts.debug={v}
        type: integer

      - category: model
        default: 1
        name: use_rotate_nms
        optional: yes
        pass-as: model.test_cfg.pts.use_rotate_nms={v}
        type: integer

      - category: model
        default: 0
        name: nms_across_levels
        optional: yes
        pass-as: model.test_cfg.pts.nms_across_levels={v}
        type: integer

      - category: model
        default: 0.01
        name: nms_thr
        optional: yes
        pass-as: model.test_cfg.pts.nms_thr={v}
        type: float

      - category: model
        default: 0.1
        name: score_thr
        optional: yes
        pass-as: model.test_cfg.pts.score_thr={v}
        type: float

      - category: model
        default: 0
        name: min_bbox_size
        optional: yes
        pass-as: model.test_cfg.pts.min_bbox_size={v}
        type: integer

      - category: model
        default: 100
        name: nms_pre
        optional: yes
        pass-as: model.test_cfg.pts.nms_pre={v}
        type: integer

      - category: model
        default: 50
        name: max_num
        optional: yes
        pass-as: model.test_cfg.pts.max_num={v}
        type: integer

      - category: dataset_type
        default: KittiDataset
        name: dataset_type
        optional: yes
        pass-as: dataset_type={v}
        type: string

      - category: test_dataloader
        default: data/kitti/
        name: data_root
        optional: yes
        pass-as: test_dataloader.dataset.data_root={v}
        type: string

      - category: class_names
        default: '[''Pedestrian'', ''Cyclist'', ''Car'']'
        multiple: separate
        multiple-separator: ','
        name: class_names
        optional: yes
        pass-as: class_names={v}
        type: string

      - category: test_dataloader
        default: '[''Pedestrian'', ''Cyclist'', ''Car'']'
        multiple: separate
        multiple-separator: ','
        name: classes
        optional: yes
        pass-as: test_dataloader.dataset.metainfo.classes={v}
        type: string

      - category: test_dataloader
        default: 1
        name: use_lidar
        optional: yes
        pass-as: test_dataloader.dataset.modality.use_lidar={v}
        type: integer

      - category: test_dataloader
        default: 1
        name: use_camera
        optional: yes
        pass-as: test_dataloader.dataset.modality.use_camera={v}
        type: integer

      - category: test_dataloader
        name: backend_args
        optional: yes
        pass-as: test_dataloader.dataset.backend_args={v}
        type: string

      - category: train_pipeline
        default: '[{''type'': ''LoadPointsFromFile'', ''coord_type'': ''LIDAR'', ''load_dim'': 4, ''use_dim'':
          4, ''backend_args'': None}, {''type'': ''LoadImageFromFile'', ''backend_args'': None}, {''type'':
          ''LoadAnnotations3D'', ''with_bbox_3d'': True, ''with_label_3d'': True}, {''type'': ''RandomResize'',
          ''scale'': [[640, 192], [2560, 768]], ''keep_ratio'': True}, {''type'': ''GlobalRotScaleTrans'',
          ''rot_range'': [-0.78539816, 0.78539816], ''scale_ratio_range'': [0.95, 1.05], ''translation_std'':
          [0.2, 0.2, 0.2]}, {''type'': ''RandomFlip3D'', ''flip_ratio_bev_horizontal'': 0.5}, {''type'':
          ''PointsRangeFilter'', ''point_cloud_range'': [0, -40, -3, 70.4, 40, 1]}, {''type'': ''ObjectRangeFilter'',
          ''point_cloud_range'': [0, -40, -3, 70.4, 40, 1]}, {''type'': ''PointShuffle''}, {''type'':
          ''Pack3DDetInputs'', ''keys'': [''points'', ''img'', ''gt_bboxes_3d'', ''gt_labels_3d'', ''gt_bboxes'',
          ''gt_labels'']}]'
        multiple: separate
        multiple-separator: ','
        name: train_pipeline
        optional: yes
        pass-as: train_pipeline={v}
        type: string

      - category: test_pipeline
        default: '[{''type'': ''LoadPointsFromFile'', ''coord_type'': ''LIDAR'', ''load_dim'': 4, ''use_dim'':
          4, ''backend_args'': None}, {''type'': ''LoadImageFromFile'', ''backend_args'': None}, {''type'':
          ''MultiScaleFlipAug3D'', ''img_scale'': [1280, 384], ''pts_scale_ratio'': 1, ''flip'': False,
          ''transforms'': [{''type'': ''Resize'', ''scale'': 0, ''keep_ratio'': True}, {''type'': ''GlobalRotScaleTrans'',
          ''rot_range'': [0, 0], ''scale_ratio_range'': [1.0, 1.0], ''translation_std'': [0, 0, 0]}, {''type'':
          ''RandomFlip3D''}, {''type'': ''PointsRangeFilter'', ''point_cloud_range'': [0, -40, -3, 70.4,
          40, 1]}]}, {''type'': ''Pack3DDetInputs'', ''keys'': [''points'', ''img'']}]'
        multiple: separate
        multiple-separator: ','
        name: test_pipeline
        optional: yes
        pass-as: test_pipeline={v}
        type: string

      - category: test_dataloader
        default: 1
        name: batch_size
        optional: yes
        pass-as: test_dataloader.batch_size={v}
        type: integer

      - category: test_dataloader
        default: 1
        name: num_workers
        optional: yes
        pass-as: test_dataloader.num_workers={v}
        type: integer

      - category: test_dataloader
        default: 0
        name: shuffle
        optional: yes
        pass-as: test_dataloader.sampler.shuffle={v}
        type: integer

      - category: train_dataloader
        default: 2
        name: times
        optional: yes
        pass-as: train_dataloader.dataset.times={v}
        type: integer

      - category: test_evaluator
        default: data/kitti/kitti_infos_val.pkl
        name: ann_file
        optional: yes
        pass-as: test_evaluator.ann_file={v}
        type: string

      - category: test_dataloader
        default: training/velodyne_reduced
        name: pts
        optional: yes
        pass-as: test_dataloader.dataset.data_prefix.pts={v}
        type: string

      - category: test_dataloader
        default: training/image_2
        name: img
        optional: yes
        pass-as: test_dataloader.dataset.data_prefix.img={v}
        type: string

      - category: test_dataloader
        default: '[{''type'': ''LoadPointsFromFile'', ''coord_type'': ''LIDAR'', ''load_dim'': 4, ''use_dim'':
          4, ''backend_args'': None}, {''type'': ''LoadImageFromFile'', ''backend_args'': None}, {''type'':
          ''MultiScaleFlipAug3D'', ''img_scale'': [1280, 384], ''pts_scale_ratio'': 1, ''flip'': False,
          ''transforms'': [{''type'': ''Resize'', ''scale'': 0, ''keep_ratio'': True}, {''type'': ''GlobalRotScaleTrans'',
          ''rot_range'': [0, 0], ''scale_ratio_range'': [1.0, 1.0], ''translation_std'': [0, 0, 0]}, {''type'':
          ''RandomFlip3D''}, {''type'': ''PointsRangeFilter'', ''point_cloud_range'': [0, -40, -3, 70.4,
          40, 1]}]}, {''type'': ''Pack3DDetInputs'', ''keys'': [''points'', ''img'']}]'
        multiple: separate
        multiple-separator: ','
        name: pipeline
        optional: yes
        pass-as: test_dataloader.dataset.pipeline={v}
        type: string

      - category: train_dataloader
        default: 0
        name: filter_empty_gt
        optional: yes
        pass-as: train_dataloader.dataset.dataset.filter_empty_gt={v}
        type: integer

      - category: test_dataloader
        default: LiDAR
        name: box_type_3d
        optional: yes
        pass-as: test_dataloader.dataset.box_type_3d={v}
        type: string

      - category: test_dataloader
        default: 1
        name: test_mode
        optional: yes
        pass-as: test_dataloader.dataset.test_mode={v}
        type: integer

      - category: visualizer
        default: '[{''type'': ''LocalVisBackend''}]'
        multiple: separate
        multiple-separator: ','
        name: vis_backends
        optional: yes
        pass-as: visualizer.vis_backends={v}
        type: string

      - category: visualizer
        default: visualizer
        name: name
        optional: yes
        pass-as: visualizer.name={v}
        type: string
    inputs:
      - name: model_weights
        default: https://download.openmmlab.com/mmdetection3d/pretrain_models/mvx_faster_rcnn_detectron2-caffe_20e_coco-pretrain_gt-sample_kitti-3-class_moderate-79.3_20200207-a4a6a3c7.pth
      - name: kitti_dataset
        default: dataset://kitti_processed/latest
